{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import contextlib\n",
    "import os\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "TRAINING_PROPORTION = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def record_time():\n",
    "    start_time = datetime.datetime.now()\n",
    "    yield\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Time taken: {result}\".format(result=end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "training = batch_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node {\n",
      "  name: \"MatMul/_0\"\n",
      "  op: \"_Send\"\n",
      "  input: \"MatMul/_0__cf__0\"\n",
      "  device: \"/job:localhost/replica:0/task:0/gpu:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"client_terminated\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"recv_device\"\n",
      "    value {\n",
      "      s: \"/job:localhost/replica:0/task:0/cpu:0\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"send_device\"\n",
      "    value {\n",
      "      s: \"/job:localhost/replica:0/task:0/gpu:0\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"send_device_incarnation\"\n",
      "    value {\n",
      "      i: 1\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"tensor_name\"\n",
      "    value {\n",
      "      s: \"edge_8_MatMul\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul/_0__cf__0\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/gpu:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\260A\\000\\000\\340A\\000\\000DB\\000\\000\\200B\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "}\n",
      "versions {\n",
      "  producer: 24\n",
      "}\n",
      ", node {\n",
      "  name: \"MatMul/_1\"\n",
      "  op: \"_Recv\"\n",
      "  device: \"/job:localhost/replica:0/task:0/cpu:0\"\n",
      "  attr {\n",
      "    key: \"client_terminated\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"recv_device\"\n",
      "    value {\n",
      "      s: \"/job:localhost/replica:0/task:0/cpu:0\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"send_device\"\n",
      "    value {\n",
      "      s: \"/job:localhost/replica:0/task:0/gpu:0\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"send_device_incarnation\"\n",
      "    value {\n",
      "      i: 1\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"tensor_name\"\n",
      "    value {\n",
      "      s: \"edge_8_MatMul\"\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"tensor_type\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"_retval_MatMul_0_0\"\n",
      "  op: \"_Retval\"\n",
      "  input: \"MatMul/_1\"\n",
      "  device: \"/job:localhost/replica:0/task:0/cpu:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"index\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "}\n",
      "versions {\n",
      "  producer: 24\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Runs the op.\n",
    "options = tf.RunOptions(output_partition_graphs=True)\n",
    "metadata = tf.RunMetadata()\n",
    "c_val = sess.run(c, options=options, run_metadata=metadata)\n",
    "\n",
    "print(metadata.partition_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'convnet', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into convnet/model.ckpt.\n",
      "INFO:tensorflow:loss = 78.688, step = 1\n",
      "INFO:tensorflow:global_step/sec: 70.962\n",
      "INFO:tensorflow:loss = 2.3965, step = 101 (1.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5033\n",
      "INFO:tensorflow:loss = 2.3594, step = 201 (1.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1539\n",
      "INFO:tensorflow:loss = 2.3359, step = 301 (1.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.8788\n",
      "INFO:tensorflow:loss = 2.3203, step = 401 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.8771\n",
      "INFO:tensorflow:loss = 2.2949, step = 501 (1.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.9487\n",
      "INFO:tensorflow:loss = 2.3164, step = 601 (1.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.7726\n",
      "INFO:tensorflow:loss = 2.3223, step = 701 (1.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.4607\n",
      "INFO:tensorflow:loss = 2.3164, step = 801 (1.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7373\n",
      "INFO:tensorflow:loss = 2.3008, step = 901 (1.545 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into convnet/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.3047.\n",
      "Time taken: 0:00:14.351050\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-26-13:00:15\n",
      "INFO:tensorflow:Restoring parameters from convnet/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-26-13:00:15\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.116, auc = 0.0422287, global_step = 1000, loss = 2.30457, precision = 0.89593, recall = 0.970966\n",
      "Time taken: 0:00:00.442434\n"
     ]
    }
   ],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    data = features['x']\n",
    "    \n",
    "    input_layer = tf.reshape(data, [-1, 32, 32, 3])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=5,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=5,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=2, strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    flat = tf.reshape(pool2, [-1, 64 * 8 * 8])\n",
    "    dense = tf.layers.dense(inputs=flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"precision\": tf.metrics.precision(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"recall\": tf.metrics.recall(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"auc\": tf.metrics.auc(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "cifar_cfr = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir='convnet')\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=10)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][:int(TRAINING_PROPORTION * len(batch_1[b'data']))], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][:int(TRAINING_PROPORTION * len(batch_1[b'labels']))]),\n",
    "    num_epochs = None,\n",
    "    shuffle = False)\n",
    "\n",
    "with record_time():\n",
    "    cifar_cfr.train(train_fn, steps=1000)\n",
    "    \n",
    "test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][int(TRAINING_PROPORTION * len(batch_1[b'data'])):], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][int(TRAINING_PROPORTION * len(batch_1[b'labels'])):]),\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "with record_time():\n",
    "    evaluation_results = cifar_cfr.evaluate(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'alexnet', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\n",
      "<tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "['File \"/home/will/anaconda2/envs/tensor/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\\n    \"__main__\", mod_spec)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/runpy.py\", line 85, in _run_code\\n    exec(code, run_globals)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\\n    app.launch_new_instance()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\\n    app.start()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\\n    ioloop.IOLoop.instance().start()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\\n    super(ZMQIOLoop, self).start()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\\n    handler_func(fd_obj, events)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\\n    self._handle_recv()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\\n    self._run_callback(callback, msg)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\\n    callback(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\\n    return self.dispatch_shell(stream, msg)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\\n    handler(stream, idents, msg)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\\n    user_expressions, allow_stdin)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\\n    interactivity=interactivity, compiler=compiler, result=result)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\\n    if self.run_code(code, result):', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)', 'File \"<ipython-input-34-c462aad82682>\", line 100, in <module>\\n    alex_cfr.train(train_fn, steps=500)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 241, in train\\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 683, in _train_model\\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 365, in MonitoredTrainingSession\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 668, in __init__\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 490, in __init__\\n    self._sess = _RecoverableSession(self._coordinated_creator)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 842, in __init__\\n    _WrappedSession.__init__(self, self._create_session())', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 847, in _create_session\\n    return self._sess_creator.create_session()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 551, in create_session\\n    self.tf_sess = self._session_creator.create_session()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 416, in create_session\\n    self._scaffold.finalize()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 196, in finalize\\n    default_ready_for_local_init_op)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 258, in get_or_default\\n    op = default_constructor()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 193, in default_ready_for_local_init_op\\n    variables.global_variables())', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 175, in wrapped\\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 144, in _add_should_use_warning\\n    wrapped = TFShouldUseWarningWrapper(x)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 101, in __init__\\n    stack = [s.strip() for s in traceback.format_stack()]']\n",
      "==================================\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into alexnet/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.8359, step = 1\n",
      "INFO:tensorflow:global_step/sec: 13.5059\n",
      "INFO:tensorflow:loss = 2.207, step = 101 (7.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5856\n",
      "INFO:tensorflow:loss = 2.2031, step = 201 (7.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5242\n",
      "INFO:tensorflow:loss = 2.1172, step = 301 (7.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5517\n",
      "INFO:tensorflow:loss = 2.0645, step = 401 (7.379 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into alexnet/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8799.\n",
      "Time taken: 0:00:37.705359\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-26-13:24:08\n",
      "INFO:tensorflow:Restoring parameters from alexnet/model.ckpt-500\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-26-13:24:08\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.3335, auc = 0.528186, global_step = 500, loss = 1.91351, precision = 0.937243, recall = 0.892239\n",
      "Time taken: 0:00:00.714399\n"
     ]
    }
   ],
   "source": [
    "def alexnet_model_fn(features, labels, mode):\n",
    "    data = features['x']\n",
    "    \n",
    "    input_layer = tf.reshape(data, [-1, 32, 32, 3])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=96,\n",
    "        kernel_size=11,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=256,\n",
    "        kernel_size=5,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=2, strides=2)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=384,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=2, strides=2)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=384,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=2, strides=2)\n",
    "    \n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=pool4,\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=2, strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    flat = tf.reshape(pool5, [-1, 256 * 1 * 1])\n",
    "    dense1 = tf.layers.dense(inputs=flat, units=2048, activation=tf.nn.relu)\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=dense1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    dense2 = tf.layers.dense(inputs=dropout1, units=2048, activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=dense2, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout2, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"precision\": tf.metrics.precision(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"recall\": tf.metrics.recall(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"auc\": tf.metrics.auc(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "directory = 'alexnet'\n",
    "try:\n",
    "    os.removedirs(directory)\n",
    "except OSError:\n",
    "    pass\n",
    "alex_cfr = tf.estimator.Estimator(model_fn=alexnet_model_fn, model_dir=directory)\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=10)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][:int(TRAINING_PROPORTION * len(batch_1[b'data']))], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][:int(TRAINING_PROPORTION * len(batch_1[b'labels']))]),\n",
    "    num_epochs = None,\n",
    "    shuffle = False)\n",
    "\n",
    "with record_time():\n",
    "    alex_cfr.train(train_fn, steps=500)\n",
    "    \n",
    "test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][int(TRAINING_PROPORTION * len(batch_1[b'data'])):], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][int(TRAINING_PROPORTION * len(batch_1[b'labels'])):]),\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "with record_time():\n",
    "    evaluation_results = alex_cfr.evaluate(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'zfnet', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from zfnet/model.ckpt-501\n",
      "INFO:tensorflow:Saving checkpoints for 502 into zfnet/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8408, step = 502\n",
      "INFO:tensorflow:global_step/sec: 7.48209\n",
      "INFO:tensorflow:loss = 1.874, step = 602 (13.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54179\n",
      "INFO:tensorflow:loss = 1.8809, step = 702 (13.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53514\n",
      "INFO:tensorflow:loss = 1.9443, step = 802 (13.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53118\n",
      "INFO:tensorflow:loss = 1.8496, step = 902 (13.278 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into zfnet/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8193.\n",
      "Time taken: 0:01:07.177503\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-26-13:40:23\n",
      "INFO:tensorflow:Restoring parameters from zfnet/model.ckpt-1001\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-26-13:40:24\n",
      "INFO:tensorflow:Saving dict for global step 1001: accuracy = 0.356, auc = 0.564751, global_step = 1001, loss = 1.77954, precision = 0.942139, recall = 0.900056\n",
      "Time taken: 0:00:00.977032\n"
     ]
    }
   ],
   "source": [
    "def zfnet_model_fn(features, labels, mode):\n",
    "    data = features['x']\n",
    "    \n",
    "    input_layer = tf.reshape(data, [-1, 32, 32, 3])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=96,\n",
    "        kernel_size=7,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=3, strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=256,\n",
    "        kernel_size=5,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=3, strides=1)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=384,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=3, strides=1)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=384,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=3, strides=1)\n",
    "    \n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=pool4,\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=3, strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    flat = tf.reshape(pool5, [-1, 256 * 4 * 4])\n",
    "    dense1 = tf.layers.dense(inputs=flat, units=2048, activation=tf.nn.relu)\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=dense1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    dense2 = tf.layers.dense(inputs=dropout1, units=2048, activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=dense2, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout2, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"precision\": tf.metrics.precision(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"recall\": tf.metrics.recall(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"auc\": tf.metrics.auc(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "directory = 'zfnet'\n",
    "try:\n",
    "    os.removedirs(directory)\n",
    "except OSError:\n",
    "    pass\n",
    "zf_cfr = tf.estimator.Estimator(model_fn=zfnet_model_fn, model_dir=directory)\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=10)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][:int(TRAINING_PROPORTION * len(batch_1[b'data']))], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][:int(TRAINING_PROPORTION * len(batch_1[b'labels']))]),\n",
    "    num_epochs = None,\n",
    "    shuffle = False)\n",
    "\n",
    "with record_time():\n",
    "    zf_cfr.train(train_fn, steps=500)\n",
    "    \n",
    "test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][int(TRAINING_PROPORTION * len(batch_1[b'data'])):], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][int(TRAINING_PROPORTION * len(batch_1[b'labels'])):]),\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "with record_time():\n",
    "    evaluation_results = zf_cfr.evaluate(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'vggnet', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\n",
      "<tf.Tensor 'report_uninitialized_variables_1/boolean_mask/Gather:0' shape=(?,) dtype=string>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "['File \"/home/will/anaconda2/envs/tensor/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\\n    \"__main__\", mod_spec)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/runpy.py\", line 85, in _run_code\\n    exec(code, run_globals)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\\n    app.launch_new_instance()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\\n    app.start()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\\n    ioloop.IOLoop.instance().start()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\\n    super(ZMQIOLoop, self).start()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\\n    handler_func(fd_obj, events)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\\n    self._handle_recv()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\\n    self._run_callback(callback, msg)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\\n    callback(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\\n    return self.dispatch_shell(stream, msg)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\\n    handler(stream, idents, msg)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\\n    user_expressions, allow_stdin)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\\n    interactivity=interactivity, compiler=compiler, result=result)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\\n    if self.run_code(code, result):', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)', 'File \"<ipython-input-55-0d8214b99ea7>\", line 123, in <module>\\n    vgg_cfr.train(train_fn, steps=500)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 241, in train\\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 683, in _train_model\\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 365, in MonitoredTrainingSession\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 668, in __init__\\n    stop_grace_period_secs=stop_grace_period_secs)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 490, in __init__\\n    self._sess = _RecoverableSession(self._coordinated_creator)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 842, in __init__\\n    _WrappedSession.__init__(self, self._create_session())', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 847, in _create_session\\n    return self._sess_creator.create_session()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 551, in create_session\\n    self.tf_sess = self._session_creator.create_session()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 416, in create_session\\n    self._scaffold.finalize()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 196, in finalize\\n    default_ready_for_local_init_op)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 258, in get_or_default\\n    op = default_constructor()', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 193, in default_ready_for_local_init_op\\n    variables.global_variables())', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 175, in wrapped\\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 144, in _add_should_use_warning\\n    wrapped = TFShouldUseWarningWrapper(x)', 'File \"/home/will/anaconda2/envs/tensor/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 101, in __init__\\n    stack = [s.strip() for s in traceback.format_stack()]']\n",
      "==================================\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into vggnet/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3008, step = 1\n",
      "INFO:tensorflow:global_step/sec: 9.16757\n",
      "INFO:tensorflow:loss = 2.3125, step = 101 (10.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.20802\n",
      "INFO:tensorflow:loss = 2.3086, step = 201 (10.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.20076\n",
      "INFO:tensorflow:loss = 2.3086, step = 301 (10.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.19531\n",
      "INFO:tensorflow:loss = 2.3086, step = 401 (10.875 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into vggnet/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.3008.\n",
      "Time taken: 0:00:56.271857\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-26-13:52:31\n",
      "INFO:tensorflow:Restoring parameters from vggnet/model.ckpt-500\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-26-13:52:32\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.1075, auc = 0.0282393, global_step = 500, loss = 2.30005, precision = 0.895907, recall = 0.98995\n",
      "Time taken: 0:00:01.214839\n"
     ]
    }
   ],
   "source": [
    "def vggnet_model_fn(features, labels, mode):\n",
    "    data = features['x']\n",
    "    \n",
    "    input_layer = tf.reshape(data, [-1, 32, 32, 3])\n",
    "    \n",
    "    conv1a = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=conv1a,\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    conv2a = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv2a,\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=2, strides=2)\n",
    "    \n",
    "    conv3a = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv3b = tf.layers.conv2d(\n",
    "        inputs=conv3a,\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=conv3b,\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=2, strides=2)\n",
    "    \n",
    "    conv4a = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv4b = tf.layers.conv2d(\n",
    "        inputs=conv4a,\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=conv4b,\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=2, strides=2)\n",
    "    \n",
    "    conv5a = tf.layers.conv2d(\n",
    "        inputs=pool4,\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv5b = tf.layers.conv2d(\n",
    "        inputs=conv5a,\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=conv5b,\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=2, strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    flat = tf.reshape(pool5, [-1, 512 * 1 * 1])\n",
    "    dense1 = tf.layers.dense(inputs=flat, units=4096, activation=tf.nn.relu)\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=dense1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    dense2 = tf.layers.dense(inputs=dropout1, units=4096, activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=dense2, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    dense3 = tf.layers.dense(inputs=dropout2, units=1000, activation=tf.nn.relu)\n",
    "    dropout3 = tf.layers.dropout(\n",
    "        inputs=dense3, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout3, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"precision\": tf.metrics.precision(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"recall\": tf.metrics.recall(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"auc\": tf.metrics.auc(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "directory = 'vggnet'\n",
    "try:\n",
    "    os.removedirs(directory)\n",
    "except OSError:\n",
    "    pass\n",
    "vgg_cfr = tf.estimator.Estimator(model_fn=vggnet_model_fn, model_dir=directory)\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=10)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][:int(TRAINING_PROPORTION * len(batch_1[b'data']))], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][:int(TRAINING_PROPORTION * len(batch_1[b'labels']))]),\n",
    "    num_epochs = None,\n",
    "    shuffle = False)\n",
    "\n",
    "with record_time():\n",
    "    vgg_cfr.train(train_fn, steps=500)\n",
    "    \n",
    "test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': np.array(batch_1[b'data'][int(TRAINING_PROPORTION * len(batch_1[b'data'])):], dtype=np.float16)},\n",
    "    y = np.array(batch_1[b'labels'][int(TRAINING_PROPORTION * len(batch_1[b'labels'])):]),\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "with record_time():\n",
    "    evaluation_results = vgg_cfr.evaluate(test_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
